{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data_loader import *\n",
    "from data_utils import *\n",
    "from model import *\n",
    "from const import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = getBagImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, num_classes):\n",
    "    tmp = np.zeros(num_classes, dtype=np.float32)\n",
    "    tmp[index] = 1.0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main evaluation code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input tensor + model network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x, y, mask = input_tensor()\n",
    "\n",
    "y_color_conv, y_shape_conv, y_opening_conv, y_strap_conv, y_pattern_conv, y_material_conv, y_handle_conv, y_decoration_conv, is_training, keep_prob = multi_label_net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_loss, shape_loss, opening_loss, strap_loss, pattern_loss, material_loss, handle_loss, decoration_loss, l2_loss, total_loss = selective_loss(y_color_conv, y_shape_conv, y_opening_conv, y_strap_conv, y_pattern_conv, y_material_conv, y_handle_conv, y_decoration_conv,y, mask)\n",
    "\n",
    "train_step = train_op(total_loss, global_step)\n",
    "\n",
    "color_mask = tf.get_collection('color_mask')[0]\n",
    "shape_mask = tf.get_collection('shape_mask')[0]\n",
    "opening_mask = tf.get_collection('opening_mask')[0]\n",
    "strap_mask = tf.get_collection('strap_mask')[0]\n",
    "pattern_mask = tf.get_collection('pattern_mask')[0]\n",
    "material_mask = tf.get_collection('material_mask')[0]\n",
    "handle_mask = tf.get_collection('handle_mask')[0]\n",
    "decoration_mask = tf.get_collection('decoration_mask')[0]\n",
    "\n",
    "y_color = tf.get_collection('y_color')[0]\n",
    "y_shape = tf.get_collection('y_shape')[0]\n",
    "y_opening = tf.get_collection('y_opening')[0]\n",
    "y_strap = tf.get_collection('y_strap')[0]\n",
    "y_pattern = tf.get_collection('y_pattern')[0]\n",
    "y_material = tf.get_collection('y_material')[0]\n",
    "y_handle = tf.get_collection('y_handle')[0]\n",
    "y_decoration = tf.get_collection('y_decoration')[0]\n",
    "\n",
    "color_correct_prediction = tf.equal(tf.argmax(y_color_conv, 1), tf.argmax(y_color, 1))\n",
    "shape_correct_prediction = tf.equal(tf.argmax(y_shape_conv, 1), tf.argmax(y_shape, 1))\n",
    "opening_correct_prediction = tf.equal(tf.argmax(y_opening_conv, 1), tf.argmax(y_opening, 1))\n",
    "strap_correct_prediction = tf.equal(tf.argmax(y_strap_conv, 1), tf.argmax(y_strap, 1))\n",
    "pattern_correct_prediction = tf.equal(tf.argmax(y_pattern_conv, 1), tf.argmax(y_pattern, 1))\n",
    "material_correct_prediction = tf.equal(tf.argmax(y_material_conv, 1), tf.argmax(y_material, 1))\n",
    "handle_correct_prediction = tf.equal(tf.argmax(y_handle_conv, 1), tf.argmax(y_handle, 1))\n",
    "decoration_correct_prediction = tf.equal(tf.argmax(y_decoration_conv, 1), tf.argmax(y_decoration, 1))\n",
    "\n",
    "color_true_pred = tf.reduce_sum(tf.cast(color_correct_prediction, dtype=tf.float32) * color_mask)\n",
    "shape_true_pred = tf.reduce_sum(tf.cast(shape_correct_prediction, dtype=tf.float32) * shape_mask)\n",
    "opening_true_pred = tf.reduce_sum(tf.cast(opening_correct_prediction, dtype=tf.float32) * opening_mask)\n",
    "strap_true_pred = tf.reduce_sum(tf.cast(strap_correct_prediction, dtype=tf.float32) * strap_mask)\n",
    "pattern_true_pred = tf.reduce_sum(tf.cast(pattern_correct_prediction, dtype=tf.float32) * pattern_mask)\n",
    "material_true_pred = tf.reduce_sum(tf.cast(material_correct_prediction, dtype=tf.float32) * material_mask)\n",
    "handle_true_pred = tf.reduce_sum(tf.cast(handle_correct_prediction, dtype=tf.float32) * handle_mask)\n",
    "decoration_true_pred = tf.reduce_sum(tf.cast(decoration_correct_prediction, dtype=tf.float32) * decoration_mask)\n",
    "\n",
    "real_test_data = []\n",
    "\n",
    "# Mask : color -> 0 , shape -> 1, opening -> 2, strap -> 3, pattern -> 4, material -> 5, handle -> 6, decoration -> 7\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][0], 16), 0.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][1], 16), 1.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][2], 16), 2.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][3], 16), 3.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][4], 16), 4.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][5], 16), 5.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][6], 16), 6.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, one_hot(label[i][7], 16), 7.0))\n",
    "\n",
    "np.random.shuffle(test_data)\n",
    "\n",
    "print('Restore model')\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, SAVE_FOLDER + 'model.ckpt')\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "train_label = []\n",
    "train_mask = []\n",
    "\n",
    "for i in range(len(real_train_data)):\n",
    "    train_img.append(real_train_data[i][0])\n",
    "    train_label.append(real_train_data[i][1])\n",
    "    train_mask.append(real_train_data[i][2])\n",
    "\n",
    "number_batch = len(real_test_data) // BATCH_SIZE\n",
    "\n",
    "color_nb_true_pred = 0\n",
    "shape_nb_true_pred = 0\n",
    "opening_nb_true_pred = 0\n",
    "strap_nb_true_pred = 0\n",
    "pattern_nb_true_pred = 0\n",
    "material_nb_true_pred = 0\n",
    "handle_nb_true_pred = 0\n",
    "decoration_nb_true_pred = 0\n",
    "\n",
    "color_nb_train = 0\n",
    "shape_nb_train = 0\n",
    "opening_nb_train = 0\n",
    "strap_nb_train = 0\n",
    "pattern_nb_train = 0\n",
    "material_nb_train = 0\n",
    "handle_nb_train = 0\n",
    "decoration_nb_train = 0\n",
    "\n",
    "for batch in range(number_batch):\n",
    "    # print('Training on batch {0}/{1}'.format(str(batch + 1), str(number_batch)))\n",
    "    top = batch * BATCH_SIZE\n",
    "    bot = min((batch + 1) * BATCH_SIZE, len(real_train_data))\n",
    "    batch_img = np.asarray(train_img[top:bot])\n",
    "    batch_label = np.asarray(train_label[top:bot])\n",
    "    batch_mask = np.asarray(train_mask[top:bot])\n",
    "    \n",
    "    batch_img = augmentation(batch_img, 64)\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        if batch_mask[i] == 0.0:\n",
    "            color_nb_train += 1\n",
    "        else:\n",
    "            if batch_mask[i] == 1.0:\n",
    "                shape_nb_train += 1\n",
    "            else:\n",
    "                if batch_mask[i] == 2.0:\n",
    "                    opening_nb_train += 1\n",
    "                else:\n",
    "                    if batch_mask[i] == 3.0:\n",
    "                        strap_nb_train += 1\n",
    "                    else:\n",
    "                        if batch_mask[i] == 4.0:\n",
    "                            pattern_nb_train += 1\n",
    "                        else:\n",
    "                            if batch_mask[i] == 5.0:\n",
    "                                material_nb_train += 1\n",
    "                            else:\n",
    "                                if batch_mask[i] == 6.0:\n",
    "                                    handle_nb_train += 1\n",
    "                                else:\n",
    "                                    decoration_nb_train +=1\n",
    "\n",
    "      \n",
    "\n",
    "    color_nb_true_pred += sess.run(color_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                               is_training: False,keep_prob: 1})\n",
    "\n",
    "    shape_nb_true_pred += sess.run(shape_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                               is_training: False, keep_prob: 1})\n",
    "\n",
    "    opening_nb_true_pred += sess.run(opening_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                   is_training: False, keep_prob: 1})\n",
    "\n",
    "    strap_nb_true_pred += sess.run(strap_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                               is_training: False, keep_prob: 1})\n",
    "\n",
    "    pattern_nb_true_pred += sess.run(pattern_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                   is_training: False, keep_prob: 1})\n",
    "\n",
    "    material_nb_true_pred += sess.run(material_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                     is_training: False, keep_prob: 1})\n",
    "\n",
    "    handle_nb_true_pred += sess.run(handle_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                     is_training: False, keep_prob:1})\n",
    "\n",
    "    decoration_nb_true_pred += sess.run(decoration_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                     is_training: False, keep_prob: 1})\n",
    "\n",
    "    sess.run(update_op,feed_dict={x: batch_img, y_: batch_label, mask: batch_mask, is_training: False, keep_prob: 1})\n",
    "\n",
    "\n",
    "\n",
    "color_train_accuracy = color_nb_true_pred * 1.0 / color_nb_train\n",
    "shape_train_accuracy = shape_nb_true_pred * 1.0 / shape_nb_train\n",
    "opening_train_accuracy = opening_nb_true_pred * 1.0 / opening_nb_train\n",
    "strap_train_accuracy = strap_nb_true_pred * 1.0 / strap_nb_train\n",
    "pattern_train_accuracy = pattern_nb_true_pred * 1.0 / pattern_nb_train\n",
    "material_train_accuracy = material_nb_true_pred * 1.0 / material_nb_train\n",
    "handle_train_accuracy = handle_nb_true_pred * 1.0 / handle_nb_train\n",
    "decoration_train_accuracy = decoration_nb_true_pred * 1.0 / decoration_nb_train\n",
    "\n",
    "print('\\n')\n",
    "print('color task train accuracy: ' + str(color_train_accuracy * 100))\n",
    "print('shape task train accuracy: ' + str(shape_train_accuracy * 100))\n",
    "print('opening task train accuracy: ' + str(opening_train_accuracy * 100))\n",
    "print('strap task train accuracy: ' + str(strap_train_accuracy * 100))\n",
    "print('pattern task train accuracy: ' + str(pattern_train_accuracy * 100))\n",
    "print('material task train accuracy: ' + str(material_train_accuracy * 100))\n",
    "print('handle task train accuracy: ' + str(handle_train_accuracy * 100))\n",
    "print('decoration task train accuracy: ' + str(decoration_train_accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
