{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data_loader import *\n",
    "from data_utils import *\n",
    "from model import *\n",
    "from const import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv................\n",
      "Load bag image...................\n",
      "Number of bag train data:  700\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_data = getBagImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, num_classes):\n",
    "    # assert index < num_classes and index >= 0\n",
    "    tmp = np.zeros(num_classes, dtype=np.float32)\n",
    "    tmp[index] = 1.0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 00:40:35.309129  3576 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0811 00:40:35.310127  3576 deprecation.py:323] From <ipython-input-4-cc918dc67598>:2: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0811 00:40:35.315113  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\model.py:8: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0811 00:40:35.319103  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\ops.py:253: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0811 00:40:35.320099  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\ops.py:141: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0811 00:40:35.397918  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\ops.py:205: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0811 00:40:35.642685  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\ops.py:181: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "W0811 00:40:35.651618  3576 deprecation.py:506] From C:\\Users\\shimd\\Desktop\\AI\\ops.py:191: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "\n",
    "x, y, mask = input_tensor()\n",
    "\n",
    "y_color_conv, y_shape_conv, y_opening_conv, y_strap_conv, y_pattern_conv, y_material_conv, y_handle_conv, y_decoration_conv, is_training, keep_prob = multi_label_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 00:40:36.024401  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\model.py:95: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0811 00:40:36.035371  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\model.py:123: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0811 00:40:36.087283  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\model.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "W0811 00:40:36.105769  3576 deprecation_wrapper.py:119] From C:\\Users\\shimd\\Desktop\\AI\\model.py:160: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "color_loss, shape_loss, opening_loss, strap_loss, pattern_loss, material_loss, handle_loss, decoration_loss, l2_loss, total_loss = selective_loss(y_color_conv, y_shape_conv, y_opening_conv, y_strap_conv, y_pattern_conv, y_material_conv, y_handle_conv, y_decoration_conv,y, mask)\n",
    "\n",
    "train_step = train_op(total_loss, global_step)\n",
    "\n",
    "color_mask = tf.get_collection('color_mask')[0]\n",
    "shape_mask = tf.get_collection('shape_mask')[0]\n",
    "opening_mask = tf.get_collection('opening_mask')[0]\n",
    "strap_mask = tf.get_collection('strap_mask')[0]\n",
    "pattern_mask = tf.get_collection('pattern_mask')[0]\n",
    "material_mask = tf.get_collection('material_mask')[0]\n",
    "handle_mask = tf.get_collection('handle_mask')[0]\n",
    "decoration_mask = tf.get_collection('decoration_mask')[0]\n",
    "\n",
    "y_color = tf.get_collection('y_color')[0]\n",
    "y_shape = tf.get_collection('y_shape')[0]\n",
    "y_opening = tf.get_collection('y_opening')[0]\n",
    "y_strap = tf.get_collection('y_strap')[0]\n",
    "y_pattern = tf.get_collection('y_pattern')[0]\n",
    "y_material = tf.get_collection('y_material')[0]\n",
    "y_handle = tf.get_collection('y_handle')[0]\n",
    "y_decoration = tf.get_collection('y_decoration')[0]\n",
    "\n",
    "color_correct_prediction = tf.equal(tf.argmax(y_color_conv, 1), tf.argmax(y_color, 1))\n",
    "shape_correct_prediction = tf.equal(tf.argmax(y_shape_conv, 1), tf.argmax(y_shape, 1))\n",
    "opening_correct_prediction = tf.equal(tf.argmax(y_opening_conv, 1), tf.argmax(y_opening, 1))\n",
    "strap_correct_prediction = tf.equal(tf.argmax(y_strap_conv, 1), tf.argmax(y_strap, 1))\n",
    "pattern_correct_prediction = tf.equal(tf.argmax(y_pattern_conv, 1), tf.argmax(y_pattern, 1))\n",
    "material_correct_prediction = tf.equal(tf.argmax(y_material_conv, 1), tf.argmax(y_material, 1))\n",
    "handle_correct_prediction = tf.equal(tf.argmax(y_handle_conv, 1), tf.argmax(y_handle, 1))\n",
    "decoration_correct_prediction = tf.equal(tf.argmax(y_decoration_conv, 1), tf.argmax(y_decoration, 1))\n",
    "\n",
    "color_true_pred = tf.reduce_sum(tf.cast(color_correct_prediction, dtype=tf.float32) * color_mask)\n",
    "shape_true_pred = tf.reduce_sum(tf.cast(shape_correct_prediction, dtype=tf.float32) * shape_mask)\n",
    "opening_true_pred = tf.reduce_sum(tf.cast(opening_correct_prediction, dtype=tf.float32) * opening_mask)\n",
    "strap_true_pred = tf.reduce_sum(tf.cast(strap_correct_prediction, dtype=tf.float32) * strap_mask)\n",
    "pattern_true_pred = tf.reduce_sum(tf.cast(pattern_correct_prediction, dtype=tf.float32) * pattern_mask)\n",
    "material_true_pred = tf.reduce_sum(tf.cast(material_correct_prediction, dtype=tf.float32) * material_mask)\n",
    "handle_true_pred = tf.reduce_sum(tf.cast(handle_correct_prediction, dtype=tf.float32) * handle_mask)\n",
    "decoration_true_pred = tf.reduce_sum(tf.cast(decoration_correct_prediction, dtype=tf.float32) * decoration_mask)\n",
    "\n",
    "real_train_data = []\n",
    "# TODO : 이 code가 맞는지 한번 실제 데이터로 돌려봐야함\n",
    "# Mask : color -> 0 , shape -> 1, opening -> 2, strap -> 3, pattern -> 4, material -> 5, handle -> 6, decoration -> 7\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][0], 0.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][1], 1.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][2], 2.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][3], 3.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][4], 4.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][5], 5.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][6], 6.0))\n",
    "for i in range(len(train_data)):\n",
    "    img = (train_data[i][0] - 128) / 255.0\n",
    "    label = train_data[i][1]\n",
    "    real_train_data.append((img, label[i][7], 7.0))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new model\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(SAVE_FOLDER + 'model.ckpt.index'):\n",
    "    print('Create new model')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('OK')\n",
    "else:\n",
    "    print('Restoring existed model')\n",
    "    saver.restore(sess, SAVE_FOLDER + 'model.ckpt')\n",
    "    print('OK')\n",
    "\n",
    "loss_summary_placeholder = tf.placeholder(tf.float32)\n",
    "tf.summary.scalar('loss', loss_summary_placeholder)\n",
    "merge_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"./summary/\")\n",
    "\n",
    "learning_rate = tf.get_collection('learning_rate')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Learning rate: 0.001000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-93bacf4b79b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m         ttl, colorl, shapel, openingl, strapl, patternl, materiall, handlel, decol, l2l, _ = sess.run([total_loss, color_loss, shape_loss, opening_loss, strap_loss,\n\u001b[0;32m     81\u001b[0m                                                                                       pattern_loss, material_loss, handle_loss, decoration_loss, l2_loss, train_step],\n\u001b[1;32m---> 82\u001b[1;33m                                                                                       feed_dict={x: batch_img, y: batch_label, mask: batch_mask, is_training: True, keep_prob: DROP_OUT_PROB})\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         color_nb_true_pred += sess.run(color_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
      "\u001b[1;32mc:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mc:\\users\\shimd\\anaconda3\\envs\\mondeique\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "current_epoch = (int)(global_step.eval() / (len(real_train_data) // BATCH_SIZE))\n",
    "for epoch in range(current_epoch + 1, NUM_EPOCHS):\n",
    "    print('Epoch:', str(epoch))\n",
    "    np.random.shuffle(real_train_data)\n",
    "    train_img = []\n",
    "    train_label = []\n",
    "    train_mask = []\n",
    "\n",
    "    for i in range(len(real_train_data)):\n",
    "        train_img.append(real_train_data[i][0])\n",
    "        train_label.append(real_train_data[i][1])\n",
    "        train_mask.append(real_train_data[i][2])\n",
    "\n",
    "    number_batch = len(real_train_data) // BATCH_SIZE\n",
    "\n",
    "    avg_ttl = []\n",
    "    avg_rgl = []\n",
    "    avg_color_loss = []\n",
    "    avg_shape_loss = []\n",
    "    avg_opening_loss = []\n",
    "    avg_strap_loss = []\n",
    "    avg_pattern_loss = []\n",
    "    avg_material_loss = []\n",
    "    avg_handle_loss = []\n",
    "    avg_decoration_loss = []\n",
    "\n",
    "    color_nb_true_pred = 0\n",
    "    shape_nb_true_pred = 0\n",
    "    opening_nb_true_pred = 0\n",
    "    strap_nb_true_pred = 0\n",
    "    pattern_nb_true_pred = 0\n",
    "    material_nb_true_pred = 0\n",
    "    handle_nb_true_pred = 0\n",
    "    decoration_nb_true_pred = 0\n",
    "\n",
    "    color_nb_train = 0\n",
    "    shape_nb_train = 0\n",
    "    opening_nb_train = 0\n",
    "    strap_nb_train = 0\n",
    "    pattern_nb_train = 0\n",
    "    material_nb_train = 0\n",
    "    handle_nb_train = 0\n",
    "    decoration_nb_train = 0\n",
    "\n",
    "    print(\"Learning rate: %f\" % learning_rate.eval())\n",
    "    for batch in range(number_batch):\n",
    "        # print('Training on batch {0}/{1}'.format(str(batch + 1), str(number_batch)))\n",
    "        top = batch * BATCH_SIZE\n",
    "        bot = min((batch + 1) * BATCH_SIZE, len(real_train_data))\n",
    "        batch_img = np.asarray(train_img[top:bot])\n",
    "        batch_label = np.asarray(train_label[top:bot])\n",
    "        batch_mask = np.asarray(train_mask[top:bot])\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if batch_mask[i] == 0.0:\n",
    "                color_nb_train += 1\n",
    "            else:\n",
    "                if batch_mask[i] == 1.0:\n",
    "                    shape_nb_train += 1\n",
    "                else:\n",
    "                    if batch_mask[i] == 2.0:\n",
    "                        opening_nb_train += 1\n",
    "                    else:\n",
    "                        if batch_mask[i] == 3.0:\n",
    "                            strap_nb_train += 1\n",
    "                        else:\n",
    "                            if batch_mask[i] == 4.0:\n",
    "                                pattern_nb_train += 1\n",
    "                            else:\n",
    "                                if batch_mask[i] == 5.0:\n",
    "                                    material_nb_train += 1\n",
    "                                else:\n",
    "                                    if batch_mask[i] == 6.0:\n",
    "                                        handle_nb_train += 1\n",
    "                                    else:\n",
    "                                        decoration_nb_train +=1\n",
    "\n",
    "        batch_img = augmentation(batch_img, 48)\n",
    "\n",
    "        ttl, colorl, shapel, openingl, strapl, patternl, materiall, handlel, decol, l2l, _ = sess.run([total_loss, color_loss, shape_loss, opening_loss, strap_loss,\n",
    "                                                                                      pattern_loss, material_loss, handle_loss, decoration_loss, l2_loss, train_step],\n",
    "                                                                                      feed_dict={x: batch_img, y: batch_label, mask: batch_mask, is_training: True, keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        color_nb_true_pred += sess.run(color_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                   is_training: True,keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        shape_nb_true_pred += sess.run(shape_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                   is_training: True, keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        opening_nb_true_pred += sess.run(opening_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                       is_training: True, keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        strap_nb_true_pred += sess.run(strap_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                   is_training: True, keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        pattern_nb_true_pred += sess.run(pattern_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                       is_training: True, keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        material_nb_true_pred += sess.run(material_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                         is_training: True, keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        handle_nb_true_pred += sess.run(handle_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                         is_training: True, keep_prob:DROP_OUT_PROB})\n",
    "\n",
    "        decoration_nb_true_pred += sess.run(decoration_true_pred, feed_dict={x: batch_img, y: batch_label, mask: batch_mask,\n",
    "                                                                         is_training: True, keep_prob: DROP_OUT_PROB})\n",
    "\n",
    "        avg_ttl.append(ttl)\n",
    "        avg_color_loss.append(colorl)\n",
    "        avg_shape_loss.append(shapel)\n",
    "        avg_opening_loss.append(openingl)\n",
    "        avg_strap_loss.append(strapl)\n",
    "        avg_pattern_loss.append(patternl)\n",
    "        avg_material_loss.append(materiall)\n",
    "        avg_handle_loss.append(handlel)\n",
    "        avg_decoration_loss.append(decol)\n",
    "\n",
    "        avg_rgl.append(l2l)\n",
    "\n",
    "    color_train_accuracy = color_nb_true_pred * 1.0 / color_nb_train\n",
    "    shape_train_accuracy = shape_nb_true_pred * 1.0 / shape_nb_train\n",
    "    opening_train_accuracy = opening_nb_true_pred * 1.0 / opening_nb_train\n",
    "    strap_train_accuracy = strap_nb_true_pred * 1.0 / strap_nb_train\n",
    "    pattern_train_accuracy = pattern_nb_true_pred * 1.0 / pattern_nb_train\n",
    "    material_train_accuracy = material_nb_true_pred * 1.0 / material_nb_train\n",
    "    handle_train_accuracy = handle_nb_true_pred * 1.0 / handle_nb_train\n",
    "    decoration_train_accuracy = decoration_nb_true_pred * 1.0 / decoration_nb_train\n",
    "\n",
    "\n",
    "    #     print('Avg_ttl: ' + str(avg_ttl))\n",
    "    #     print('loss_summary_placeholder: ' + str(loss_summary_placeholder))\n",
    "    #     print('merge_summary: ' + str(merge_summary))\n",
    "\n",
    "    summary = sess.run(merge_summary, feed_dict={loss_summary_placeholder: avg_ttl})\n",
    "    writer.add_summary(summary, global_step=epoch)\n",
    "\n",
    "    with open('log.csv', 'w+') as f:\n",
    "        # epochs, color_train_accuracy, shape_train_accuracy, opening_train_accuracy,\n",
    "        # avg_color_loss, avg_shape_loss, avg_opening_loss, avg_ttl, avg_rgl\n",
    "        f.write('{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14}, {15}, {16}\\n'.format(current_epoch, color_train_accuracy, shape_train_accuracy, opening_train_accuracy,\n",
    "                                                                                            strap_train_accuracy, pattern_train_accuracy, material_train_accuracy,\n",
    "                                                                                            avg_color_loss, avg_shape_loss, avg_opening_loss, avg_strap_loss, avg_pattern_loss,\n",
    "                                                                                            avg_material_loss, avg_handle_loss, avg_decoration_loss, avg_ttl, avg_rgl))\n",
    "\n",
    "    print('color task train accuracy: ' + str(color_train_accuracy * 100))\n",
    "    print('shape task train accuracy: ' + str(shape_train_accuracy * 100))\n",
    "    print('opening task train accuracy: ' + str(opening_train_accuracy * 100))\n",
    "    print('strap task train accuracy: ' + str(strap_train_accuracy * 100))\n",
    "    print('pattern task train accuracy: ' + str(pattern_train_accuracy * 100))\n",
    "    print('material task train accuracy: ' + str(material_train_accuracy * 100))\n",
    "    print('handle task train accuracy: ' + str(handle_train_accuracy * 100))\n",
    "    print('decoration task train accuracy: ' + str(decoration_train_accuracy * 100))\n",
    "\n",
    "    print('Total loss: ' + str(avg_ttl) + '. L2-loss: ' + str(avg_rgl))\n",
    "    print('Color loss: ' + str(avg_color_loss))\n",
    "    print('Shape loss: ' + str(avg_shape_loss))\n",
    "    print('opening loss: ' + str(avg_opening_loss))\n",
    "    print('strap loss: ' + str(avg_strap_loss))\n",
    "    print('pattern loss: ' + str(avg_pattern_loss))\n",
    "    print('material loss: ' + str(avg_material_loss))\n",
    "    print('handle loss: ' + str(avg_handle_loss))\n",
    "    print('decoration loss: ' + str(avg_decoration_loss))\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    saver.save(sess, const.SAVE_FOLDER + 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
